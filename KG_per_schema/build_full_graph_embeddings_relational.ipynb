{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Graph Neural Networks with PyG on Node Classification, Link Prediction, and Anomaly Detection\n",
        "\n",
        "In this notebook, we will review PyG code implementations on major graph problems including node classification, link prediction, and anomaly detection."
      ],
      "metadata": {
        "id": "3arhXozI_HZa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "import torch\n",
        "version = torch.__version__\n",
        "i = version.find('+')\n",
        "version = version[:i-1] + '0' + version[i:]\n",
        "url = 'https://data.pyg.org/whl/torch-' + version + '.html'\n",
        "\n",
        "!pip install torch-scatter -f $url\n",
        "!pip install torch-sparse -f $url\n",
        "!pip install torch-geometric\n",
        "!pip install torch-cluster -f $url\n",
        "!pip install pygod\n",
        "!pip install --upgrade scipy"
      ],
      "metadata": {
        "id": "TycT-5Vy3w5m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yundK90U3Pxt"
      },
      "outputs": [],
      "source": [
        "from torch_geometric.data import Data\n",
        "from torch_geometric.utils import to_networkx\n",
        "import torch_geometric.transforms as T\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import networkx as nx\n",
        "import random\n",
        "import numpy as np\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def make_deterministic(random_seed = 123):\n",
        "    torch.manual_seed(random_seed)\n",
        "    torch.cuda.manual_seed(random_seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    np.random.seed(random_seed)\n",
        "\n",
        "make_deterministic()"
      ],
      "metadata": {
        "id": "LeB4mtlqGm0_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Loading Data\n",
        "We are using [Cora dataset](https://paperswithcode.com/dataset/cora) for the following GCN implementations. The Cora dataset is a paper citation network data that consists of 2,708 scientific publications. Each node in the graph represents each publication and a pair of nodes is connected with an edge if one paper cites the other.\n",
        "\n",
        "Through this notebook, we are using [PyG (Pytorch Geometric)](https://www.pyg.org/) to implement GCN which is one of the popular GNN libraries. The Cora dataset can also be loaded using PyG module."
      ],
      "metadata": {
        "id": "5BejInm66nw5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def show_graph_stats(graph):\n",
        "    print(f\"Number of nodes: {graph.x.shape[0]}\")\n",
        "    print(f\"Number of node features: {graph.x.shape[1]}\")\n",
        "    print(f\"Number of edges: {graph.edge_index.shape[1]}\")\n"
      ],
      "metadata": {
        "id": "MCXoETTM78w_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.nn import RGCNConv, GCNConv\n",
        "import torch.nn.functional as F\n",
        "class Net(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
        "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
        "\n",
        "    def encode(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index).relu()\n",
        "        return self.conv2(x, edge_index)\n",
        "\n",
        "    def decode(self, z, edge_label_index):\n",
        "        return (z[edge_label_index[0]] * z[edge_label_index[1]]).sum(\n",
        "            dim=-1\n",
        "        )  # product of a pair of nodes on each edge\n",
        "\n",
        "    def decode_all(self, z):\n",
        "        prob_adj = z @ z.t()\n",
        "        return (prob_adj > 0).nonzero(as_tuple=False).t()\n",
        "\n",
        "class RGCN(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels, num_relations):\n",
        "        super().__init__()\n",
        "        self.conv1 = RGCNConv(in_channels, hidden_channels, num_relations, num_bases=min(num_relations, 10))\n",
        "        self.conv2 = RGCNConv(hidden_channels, out_channels, num_relations, num_bases=min(num_relations, 10))\n",
        "\n",
        "    def encode(self, x, edge_index, edge_type):\n",
        "        x = self.conv1(x, edge_index, edge_type).relu()\n",
        "        return self.conv2(x, edge_index, edge_type)\n",
        "\n",
        "    def decode(self, z, edge_label_index):\n",
        "        return (z[edge_label_index[0]] * z[edge_label_index[1]]).sum(dim=-1)\n",
        "\n",
        "    def decode_all(self, z):\n",
        "        prob_adj = z @ z.t()\n",
        "        return (prob_adj > 0).nonzero(as_tuple=False).t()"
      ],
      "metadata": {
        "id": "Jv8nt7FPeITy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "from torch_geometric.utils import negative_sampling\n",
        "\n",
        "\n",
        "def train_link_predictor(\n",
        "    model, train_data, val_data, optimizer, criterion, n_epochs=1000, patience=50\n",
        "):\n",
        "    best_val_auc = 0  # Best observed validation AUC\n",
        "    epochs_without_improvement = 0  # Counter for epochs without improvement\n",
        "\n",
        "    for epoch in range(1, n_epochs + 1):\n",
        "        # Train the model\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Pass edge_type to the model's encode method if RGCN model\n",
        "        if isinstance(model, RGCN):\n",
        "            z = model.encode(x=train_data.x, edge_index=train_data.edge_index, edge_type=train_data.edge_types)\n",
        "        else:\n",
        "            z = model.encode(x=train_data.x, edge_index=train_data.edge_index)\n",
        "\n",
        "        # Sample negatives\n",
        "        neg_edge_index = negative_sampling(\n",
        "            edge_index=train_data.edge_index, num_nodes=train_data.num_nodes,\n",
        "            num_neg_samples=train_data.edge_label_index.size(1), method='sparse')\n",
        "\n",
        "        edge_label_index = torch.cat([train_data.edge_label_index, neg_edge_index], dim=-1)\n",
        "        edge_label = torch.cat([\n",
        "            train_data.edge_label,\n",
        "            train_data.edge_label.new_zeros(neg_edge_index.size(1))\n",
        "        ], dim=0)\n",
        "\n",
        "        # Compute loss\n",
        "        out = model.decode(z, edge_label_index).view(-1)\n",
        "        loss = criterion(out, edge_label)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Compute validation AUC\n",
        "        val_auc = eval_link_predictor(model, val_data)\n",
        "\n",
        "        # Check for improvement\n",
        "        if val_auc > best_val_auc:\n",
        "            best_val_auc = val_auc  # Update best validation AUC\n",
        "            epochs_without_improvement = 0  # Reset counter\n",
        "        else:\n",
        "            epochs_without_improvement += 1  # Increment counter\n",
        "\n",
        "        if epoch % 10 == 0:\n",
        "            print(f\"Epoch: {epoch:03d}, Train Loss: {loss:.3f}, Val AUC: {val_auc:.3f}\")\n",
        "\n",
        "        # Check for early stopping\n",
        "        if epochs_without_improvement >= patience:\n",
        "            print(f\"No improvement in validation AUC for {patience} epochs, stopping\")\n",
        "            break\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def eval_link_predictor(model, data):\n",
        "\n",
        "    model.eval()\n",
        "    if isinstance(model, RGCN):\n",
        "      z = model.encode(data.x, data.edge_index, data.edge_types)\n",
        "    else:\n",
        "      z = model.encode(data.x, data.edge_index)\n",
        "    out = model.decode(z, data.edge_label_index).view(-1).sigmoid()\n",
        "\n",
        "    # print(out.cpu().numpy()[:10])\n",
        "    # print(data.edge_label.cpu().numpy()[:10])\n",
        "\n",
        "\n",
        "    return roc_auc_score(data.edge_label.cpu().numpy(), out.cpu().numpy())"
      ],
      "metadata": {
        "id": "X-Za2MkyBSic"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "from google.colab import drive\n",
        "import glob\n",
        "import os\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "pathnames = [path for path in glob.glob('/content/drive/MyDrive/full_graphs/paper_update/*.pth')]\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6vxnd3nCa5Um",
        "outputId": "05931592-68e4-40c9-8ec9-d12019a663cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for path in pathnames:\n",
        "  graph = torch.load(path)\n",
        "  show_graph_stats(graph)\n",
        "  graph = graph.to(device)\n",
        "\n",
        "  split = T.RandomLinkSplit(\n",
        "      num_val=0.05,\n",
        "      num_test=0.1,\n",
        "      is_undirected=True,\n",
        "      add_negative_train_samples=False,\n",
        "      neg_sampling_ratio=1.0,\n",
        "  )\n",
        "  train_data, val_data, test_data = split(graph)\n",
        "\n",
        "  use_relation_types = False\n",
        "\n",
        "  if use_relation_types:\n",
        "    num_relations = len(graph.edge_types.unique())\n",
        "    model = RGCN(graph.x.shape[1], 128, 64, num_relations).to(device)\n",
        "  else:\n",
        "    model = Net(graph.x.shape[1], 128, 64).to(device)\n",
        "\n",
        "  optimizer = torch.optim.Adam(params=model.parameters(), lr=0.0001)\n",
        "  criterion = torch.nn.BCEWithLogitsLoss()\n",
        "\n",
        "  model = train_link_predictor(model, train_data, val_data, optimizer, criterion)\n",
        "\n",
        "  test_auc = eval_link_predictor(model, test_data)\n",
        "  print(f\"Test: {test_auc:.3f}\")\n",
        "\n",
        "  # get the embeddings\n",
        "  with torch.no_grad():  # we don't need gradients for this operation\n",
        "      embeddings = model.encode(graph.x, graph.edge_index)\n",
        "\n",
        "  # Save learned embeddings as the dataset to disk\n",
        "  graph.x = embeddings\n",
        "  graph_name = os.path.basename(path).replace('.pth', '') + \"_embedded.pth\"\n",
        "  torch.save(graph, '/content/drive/MyDrive/embedded/' + graph_name)"
      ],
      "metadata": {
        "id": "nrvT126xd0sN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6790a0a-7e47-41b4-9ee1-99c65b56c50a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of nodes: 6449\n",
            "Number of node features: 5\n",
            "Number of edges: 8646\n",
            "Epoch: 010, Train Loss: 0.477, Val AUC: 0.896\n",
            "Epoch: 020, Train Loss: 0.477, Val AUC: 0.897\n",
            "Epoch: 030, Train Loss: 0.475, Val AUC: 0.897\n",
            "Epoch: 040, Train Loss: 0.476, Val AUC: 0.897\n",
            "Epoch: 050, Train Loss: 0.478, Val AUC: 0.897\n",
            "Epoch: 060, Train Loss: 0.477, Val AUC: 0.897\n",
            "Epoch: 070, Train Loss: 0.474, Val AUC: 0.897\n",
            "Epoch: 080, Train Loss: 0.471, Val AUC: 0.897\n",
            "No improvement in validation AUC for 50 epochs, stopping\n",
            "Test: 0.886\n",
            "Number of nodes: 6918\n",
            "Number of node features: 5\n",
            "Number of edges: 9282\n",
            "Epoch: 010, Train Loss: 0.480, Val AUC: 0.899\n",
            "Epoch: 020, Train Loss: 0.479, Val AUC: 0.899\n",
            "Epoch: 030, Train Loss: 0.479, Val AUC: 0.898\n",
            "Epoch: 040, Train Loss: 0.476, Val AUC: 0.898\n",
            "Epoch: 050, Train Loss: 0.476, Val AUC: 0.897\n",
            "Epoch: 060, Train Loss: 0.478, Val AUC: 0.897\n",
            "No improvement in validation AUC for 50 epochs, stopping\n",
            "Test: 0.896\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cdoH39Z2Xi5C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FmK2k70OXpfP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}